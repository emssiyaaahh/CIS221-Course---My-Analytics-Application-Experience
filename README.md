# My Analytics Application Experience

Welcome! ðŸ‘‹ This is my midterms portfolio for CIS221 â€” a collection of my hands-on work with data analytics, statistical analysis, and machine learning concepts.

---

## What's In Here?

### Core Analytics Work
- **Correlation Practice Part 1, 2, & 3.ipynb** - My journey understanding how variables relate to each other. Sounds simple, but it's deceptively nuanced once you get into multicollinearity and non-linear relationships.
- **Data Cleaning through Imputation Techniques.ipynb** - Real talk: most analytics work is actually just data cleaning. This notebook covers the different ways to handle missing data without messing up your analysis.
- **Loading, Organizing, Storing Data 1 & 2.ipynb** - Practical exercises on setting up data pipelines properly. Think of it as the foundation for any BI project.
- **Quick Descriptives One.ipynb** - Summarizing data effectively. Useful for creating dashboards and business reports.

---

## What Actually Happened During Midterms?

### What are the challenges I experienced in doing Exploratory Data Analysis, Inferential Regression Analysis, and Regression for Machine Learning?

During my midterm projects, I found that the biggest challenges weren't in the complex formulas, but in the practical realities of working with data. I was surprised by how much time I spent just dealing with messy dataâ€”things like missing values, inconsistent formatting, and outliers that you don't typically see in textbook examples. It was also a humbling experience to realize how easy it is to misinterpret correlation as causation, especially when you're staring at a high correlation number and are eager to find a meaningful insight. Finally, I fell into the classic trap with machine learning where my model seemed to perform brilliantly, only to find out it was overfitted and couldn't generalize to new, unseen data.

---

### What could have been the reasons why such an event happened? (you could bring in some theory into it). What are the things we have learned so that we can improve from this experience?

Looking back, I realized these issues are a direct result of how data is handled in the real world, which connects directly to my information systems studies. Data is often messy because it comes from different systems that weren't designed to work together, or because of years of inconsistent manual data entry. This experience taught me that good data governance isn't just a theoretical concept; it's the foundation of any reliable analysis. I also learned that statistical tools don't replace critical thinking. You have to constantly ask "why" and consider the business context, otherwise the numbers can be misleading. The key lesson for me was that a simple, explainable model that stakeholders can trust is often more valuable than a complex, black-box one, even if its accuracy is slightly lower.

---

### Now what do I need to do better next time?

Moving forward, I'm going to change my approach. My new rule is to start every project with a thorough data audit to understand its quality and limitations before I write a single line of analysis code. I'll be more intentional about documenting my assumptions and the reasoning behind my decisions, especially why I choose a specific cleaning method or feature. Instead of just chasing a high accuracy score, I'll use a variety of metrics to get a more holistic view of my model's performance and focus on building solutions that are not only statistically sound but also interpretable and useful for making real-world decisions.

---

## The Technical Stack

- **Python** - For all the actual analysis
- **Jupyter Notebooks** - Where the experimentation happens
- **Pandas & NumPy** - Data manipulation and numerical work
- **Scikit-learn** - Machine learning algorithms
- **Matplotlib & Seaborn** - Visualizations for exploration
- **SciPy** - Statistical testing

For real projects, I'd integrate this with **Power BI** or **Streamlit** for dashboards, and **PostgreSQL** or **Flectra** for data storage and management.

---

## How to Navigate This Repo

1. Start with the **EDA notebooks** (Correlation Practice series) to see how I explored the data
2. Check out the **Data Cleaning** notebook to see my imputation decisions
3. Review the **Data Management** notebooks for pipeline practices
4. Read the comments in each cellâ€”I tried to explain my thinking throughout

Each notebook is independent, so you can pick any one and run it without dependencies.

---

## My Honest Reflection

Honestly, this activities shifted my perspective on what analytics is really about. I used to think it was mostly about memorizing the right Python libraries or statistical tests, but Iâ€™ve realized itâ€™s actually about understanding the entire systemâ€”from the quality of the data to the actual business problem you're trying to solve. As an IS student, I can now see the direct link between these messy notebooks and real-world concepts like database design and data governance strategies. The errors and roadblocks I hit weren't just failures; they were exactly what taught me the most. Iâ€™m walking away from this experience understanding that successful analytics isn't just about getting a high accuracy score, but about being curious, understanding the "why" behind the data, and connecting technical skills to real business needs.

---

**Course:** CIS 221 - Analytics Application
**Activity:** FJournal 1 - Analytics Application Experience  
**Framework:** CRISP-DM Approach  
**Created:** November 28, 2025

**License:** GPL-3.0

---

Feel free to reach out if you have questions about any of this work or want to discuss the concepts further. Always happy to talk data! ðŸ“Š 
